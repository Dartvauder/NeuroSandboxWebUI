{
  "Enter your request": "输入您的请求",
  "Enter your system prompt": "输入您的系统提示",
  "Record your request (optional)": "记录您的请求（可选）",
  "Select LLM model": "选择LLM模型",
  "Select LoRA model (optional)": "选择LoRA模型（可选）",
  "LLM and TTS Settings": "LLM和TTS设置",
  "TTS and STT Settings": "TTS和STT设置",
  "Select existing chat (optional)": "选择现有聊天（可选）",
  "Physical batch size (N_UBATCH) for llama type models": "llama 类型模型的物理批量大小 (N_UBATCH)",
  "RoPE base frequency (FREQ_BASE) for llama type models": "llama 类型模型的 RoPE 基础频率 (FREQ_BASE)",
  "RoPE frequency scaling factor (FREQ_SCALE) for llama type models": "llama 类型模型的 RoPE 频率缩放因子 (FREQ_SCALE)",
  "Upload your video (for Multimodal)": "上传您的视频（用于多模态）",
  "Upload your audio (for Multimodal)": "上传您的音频（用于多模态）",
  "Max tokens": "最大令牌数",
  "Min length": "最小长度",
  "Context size (N_CTX) for llama type models": "llama类型模型的上下文大小 (N_CTX)",
  "Context batch (N_BATCH) for llama type models": "llama类型模型的上下文批次 (N_BATCH)",
  "Min P": "最小P值",
  "Typical P": "典型P值",
  "Enable MultiDiffusion": "启用多重扩散",
  "Enable Circular padding (for MultiDiffusion)": "启用循环填充（用于多重扩散）",
  "Select quantize model type": "选择量化模型类型",
  "Stop sequences (optional)": "停止序列（可选）",
  "TTS Repetition penalty": "TTS重复惩罚",
  "TTS Length penalty": "TTS长度惩罚",
  "Enable Do Sample": "启用采样",
  "Enable Early Stopping": "启用提前停止",
  "Repetition penalty": "重复惩罚",
  "Frequency penalty": "频率惩罚",
  "Presence penalty": "存在惩罚",
  "Length penalty": "长度惩罚",
  "No repeat ngram size": "不重复的n元组大小",
  "Num beams": "束搜索数量",
  "Num return sequences": "返回序列数量",
  "SeamlessM4Tv2 Settings": "SeamlessM4Tv2设置",
  "Select TTS output format": "选择TTS输出格式",
  "Select STT output format": "选择STT输出格式",
  "Enable WebSearch": "启用网络搜索",
  "Enable LibreTranslate": "启用LibreTranslate",
  "Select target language": "选择目标语言",
  "Enable OpenParse": "启用OpenParse",
  "Upload PDF file (for OpenParse)": "上传PDF文件（用于OpenParse）",
  "Enable Multimodal": "启用多模态",
  "Upload your image (for Multimodal)": "上传您的图片（用于多模态）",
  "Enable TTS": "启用TTS",
  "<h3>LLM Settings</h3>": "LLM设置",
  "Max length (for transformers type models)": "最大长度（用于transformers类型模型）",
  "Max tokens (for llama type models)": "最大令牌数（用于llama类型模型）",
  "Temperature": "温度",
  "Top P": "Top P",
  "Select chat history format": "选择聊天历史格式",
  "<h3>TTS Settings</h3>": "TTS设置",
  "Select voice": "选择声音",
  "Select language": "选择语言",
  "TTS Temperature": "TTS温度",
  "TTS Top P": "TTS Top P",
  "TTS Top K": "TTS Top K",
  "TTS Speed": "TTS速度",
  "Select output format": "选择输出格式",
  "LLM text response": "LLM文本回复",
  "LLM audio response": "LLM音频回复",
  "NeuroSandboxWebUI - LLM": "NeuroSandboxWebUI - LLM",
  "This user interface allows you to enter any text or audio and receive generated response. You can select the LLM model, avatar, voice and language for tts from the drop-down lists. You can also customize the model settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本或音频并接收生成的回复。您可以从下拉列表中选择LLM模型、头像、声音和TTS的语言。您还可以使用滑块自定义模型设置。试试看会发生什么！",
  "Stop": "停止",
  "Generate": "生成",
  "Enter text for TTS": "输入TTS文本",
  "Record audio for STT": "录制STT音频",
  "TTS Audio": "TTS音频",
  "STT Text": "STT文本",
  "(prompt:x.x) for Weighting": "(prompt:x.x) 用于加权",
  "NeuroSandboxWebUI - TTS-STT": "NeuroSandboxWebUI - TTS-STT",
  "This user interface allows you to enter text for Text-to-Speech(CoquiTTS) and record audio for Speech-to-Text(OpenAIWhisper). For TTS, you can select the voice and language, and customize the generation settings from the sliders. For STT, simply record your audio and the spoken text will be displayed. Try it and see what happens!": "此用户界面允许您输入文本用于文本到语音转换（CoquiTTS）和录制音频用于语音到文本转换（OpenAIWhisper）。对于TTS，您可以选择声音和语言，并使用滑块自定义生成设置。对于STT，只需录制您的音频，spoken文本将被显示。试试看会发生什么！",
  "Enter text to synthesize": "输入要合成的文本",
  "Synthesized speech": "合成的语音",
  "Message": "消息",
  "NeuroSandboxWebUI - MMS Text-to-Speech": "NeuroSandboxWebUI - MMS文本到语音",
  "Generate speech from text using MMS TTS models.": "使用MMS TTS模型从文本生成语音。",
  "Upload or record audio": "上传或录制音频",
  "Transcription": "转录",
  "NeuroSandboxWebUI - MMS Speech-to-Text": "NeuroSandboxWebUI - MMS语音到文本",
  "Transcribe speech to text using MMS STT model.": "使用MMS STT模型将语音转录为文本。",
  "Text-to-Speech": "文本到语音",
  "Speech-to-Text": "语音到文本",
  "Input Type": "输入类型",
  "Input Text": "输入文本",
  "Input Audio": "输入音频",
  "Select source language": "选择源语言",
  "Source Language": "源语言",
  "Target Language": "目标语言",
  "Dataset Language": "数据集语言",
  "Enable Speech Generation": "启用语音生成",
  "Speaker ID": "说话人ID",
  "Text Num Beams": "文本束搜索数",
  "Enable Text Sampling": "启用文本采样",
  "Enable Speech Sampling": "启用语音采样",
  "Speech Temperature": "语音温度",
  "Text Temperature": "文本温度",
  "Enable Both Generation": "启用两种生成",
  "Task Type": "任务类型",
  "Text Output Format": "文本输出格式",
  "Audio Output Format": "音频输出格式",
  "Generated Text": "生成的文本",
  "Generated Audio": "生成的音频",
  "NeuroSandboxWebUI - SeamlessM4Tv2": "NeuroSandboxWebUI - SeamlessM4Tv2",
  "This interface allows you to use the SeamlessM4Tv2 model for various translation and speech tasks.": "此界面允许您使用SeamlessM4Tv2模型进行各种翻译和语音任务。",
  "Translate": "翻译",
  "Enter text to translate": "输入要翻译的文本",
  "Enable translate history save": "启用翻译历史保存",
  "Select translate history format": "选择翻译历史格式",
  "Upload text file (optional)": "上传文本文件（可选）",
  "Translated text": "翻译后的文本",
  "Additional LibreTranslate Settings": "额外的LibreTranslate设置",
  "NeuroSandboxWebUI - LibreTranslate": "NeuroSandboxWebUI - LibreTranslate",
  "This user interface allows you to enter text and translate it using LibreTranslate. Select the source and target languages and click Submit to get the translation. Try it and see what happens!": "此用户界面允许您输入文本并使用LibreTranslate进行翻译。选择源语言和目标语言，然后点击提交以获取翻译。试试看会发生什么！",
  "Enter your prompt": "输入您的提示",
  "Enter your negative prompt": "输入您的负面提示",
  "Select StableDiffusion model": "选择StableDiffusion模型",
  "Select VAE model (optional)": "选择VAE模型（可选）",
  "Select LORA models (optional)": "选择LORA模型（可选）",
  "LoRA Scales": "LoRA比例",
  "Select Embedding models (optional)": "选择嵌入模型（可选）",
  "<h3>StableDiffusion Settings</h3>": "StableDiffusion设置",
  "StableDiffusion Settings": "StableDiffusion设置",
  "Strength": "强度",
  "Additional StableDiffusion Settings": "额外的StableDiffusion设置",
  "Select scheduler": "选择调度器",
  "Steps": "步骤",
  "CFG": "CFG",
  "Width": "宽度",
  "Height": "高度",
  "Clip skip": "Clip跳过",
  "Number of images to generate": "要生成的图像数量",
  "Seed (optional)": "种子（可选）",
  "Stop generation": "停止生成",
  "Enable FreeU": "启用FreeU",
  "FreeU-S1": "FreeU-S1",
  "FreeU-S2": "FreeU-S2",
  "FreeU-B1": "FreeU-B1",
  "FreeU-B2": "FreeU-B2",
  "Enable SAG": "启用SAG",
  "SAG Scale": "SAG比例",
  "Enable PAG": "启用PAG",
  "PAG Scale": "PAG比例",
  "Enable Token Merging": "启用令牌合并",
  "Token Merging Ratio": "令牌合并比率",
  "Enable DeepCache": "启用DeepCache",
  "DeepCache Interval": "DeepCache间隔",
  "DeepCache BranchID": "DeepCache分支ID",
  "Enable T-GATE": "启用T-GATE",
  "T-GATE steps": "T-GATE步骤",
  "Enable MagicPrompt": "启用MagicPrompt",
  "MagicPrompt Max New Tokens": "MagicPrompt最大新令牌数",
  "Generated images": "生成的图像",
  "Generation process": "生成过程",
  "NeuroSandboxWebUI - StableDiffusion (txt2img)": "NeuroSandboxWebUI - StableDiffusion（文本到图像）",
  "This user interface allows you to enter any text and generate images using StableDiffusion. You can select the model and customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本并使用StableDiffusion生成图像。您可以选择模型并使用滑块自定义生成设置。试试看会发生什么！",
  "Initial image": "初始图像",
  "Strength (Initial image)": "强度（初始图像）",
  "NeuroSandboxWebUI - StableDiffusion (img2img)": "NeuroSandboxWebUI - StableDiffusion（图像到图像）",
  "This user interface allows you to enter any text and image to generate new images using StableDiffusion. You can select the model and customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本和图像，使用StableDiffusion生成新图像。您可以选择模型并使用滑块自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - StableDiffusion (depth2img)": "NeuroSandboxWebUI - StableDiffusion（深度到图像）",
  "This user interface allows you to enter a prompt, an initial image to generate depth-aware images using StableDiffusion. Try it and see what happens!": "此用户界面允许您输入提示和初始图像，使用StableDiffusion生成深度感知图像。试试看会发生什么！",
  "Input image": "输入图像",
  "Num inference steps": "推理步骤数",
  "Ensemble size": "集成大小",
  "Depth image": "深度图像",
  "Normals image": "法线图像",
  "NeuroSandboxWebUI - Marigold": "NeuroSandboxWebUI - Marigold",
  "This interface allows you to generate depth and normal maps using Marigold models. Upload an image and adjust the inference steps and ensemble size. The model will generate both depth and normal maps.": "此界面允许您使用Marigold模型生成深度和法线贴图。上传图像并调整推理步骤和集成大小。模型将生成深度和法线贴图。",
  "NeuroSandboxWebUI - StableDiffusion (pix2pix)": "NeuroSandboxWebUI - StableDiffusion（像素到像素）",
  "This user interface allows you to enter a prompt and an initial image to generate new images using Pix2Pix. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入提示和初始图像，使用Pix2Pix生成新图像。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "Select ControlNet model": "选择ControlNet模型",
  "ControlNet conditioning scale": "ControlNet条件缩放",
  "NeuroSandboxWebUI - StableDiffusion (controlnet)": "NeuroSandboxWebUI - StableDiffusion（ControlNet）",
  "This user interface allows you to generate images using ControlNet models. Upload an initial image, enter a prompt, select a Stable Diffusion model, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用ControlNet模型生成图像。上传初始图像，输入提示，选择Stable Diffusion模型，并自定义生成设置。试试看会发生什么！",
  "Prompt (optional)": "提示（可选）",
  "Upscale size": "放大尺寸",
  "Upscale-latent Settings": "潜在空间放大设置",
  "Pix2Pix Settings": "Pix2Pix设置",
  "Inpaint Settings": "修复设置",
  "Outpaint Settings": "扩绘设置",
  "DiffEdit Settings": "DiffEdit设置",
  "SD-Video Settings": "SD-Video设置",
  "LDM3D Settings": "LDM3D设置",
  "StableDiffusion3 Settings": "StableDiffusion3设置",
  "ControlNet control images": "ControlNet控制图像",
  "StableCascade Settings": "StableCascade设置",
  "Kandinsky Settings": "Kandinsky设置",
  "Generated image": "生成的图像",
  "Generated image (Stage I)": "生成的图像（第一阶段）",
  "Generated image (Stage II)": "生成的图像（第二阶段）",
  "Generated image (Stage III)": "生成的图像（第三阶段）",
  "Max Sequence Length": "最大序列长度",
  "Wav2Lip Settings": "Wav2Lip设置",
  "Pads": "填充",
  "Strength (Video to enhance)": "强度（要增强的视频）",
  "StableFast3D Settings": "StableFast3D设置",
  "Initial image (optional)": "初始图像（可选）",
  "Inference steps": "推理步骤",
  "AudioCraft Settings": "AudioCraft设置",
  "NeuroSandboxWebUI - StableDiffusion (upscale-latent)": "NeuroSandboxWebUI - StableDiffusion（潜在空间放大）",
  "This user interface allows you to upload an image and latent-upscale it using x2 or x4 upscale factor": "此用户界面允许您上传图像并使用2倍或4倍放大因子在潜在空间中放大它",
  "Upscale": "放大",
  "Upscale factor": "放大因子",
  "Minimum size": "最小尺寸",
  "Prompt": "提示",
  "Negative Prompt": "负面提示",
  "Refined image": "精细化图像",
  "NeuroSandboxWebUI - SDXL Refiner": "NeuroSandboxWebUI - SDXL精细化器",
  "This interface allows you to refine images using the SDXL Refiner model. Enter a prompt, upload an initial image, and see the refined result.": "此界面允许您使用SDXL精细化器模型细化图像。输入提示，上传初始图像，查看精细化结果。",
  "Refine": "精细化",
  "Mask image": "蒙版图像",
  "Mask Blur Factor": "蒙版模糊因子",
  "Select Inpaint model": "选择修复模型",
  "NeuroSandboxWebUI - StableDiffusion (inpaint)": "NeuroSandboxWebUI - StableDiffusion（修复）",
  "This user interface allows you to enter a prompt, an initial image, and a mask image to inpaint using StableDiffusion. You can select the model and customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入提示、初始图像和蒙版图像，使用StableDiffusion进行修复。您可以选择模型并使用滑块自定义生成设置。试试看会发生什么！",
  "Outpaint direction": "扩绘方向",
  "Expansion percentage": "扩展百分比",
  "NeuroSandboxWebUI - StableDiffusion (outpaint)": "NeuroSandboxWebUI - StableDiffusion（扩绘）",
  "This user interface allows you to expand an existing image using outpainting with StableDiffusion. Upload an image, enter a prompt, select a model type and direction to expand, and customize the generation settings. The image will be expanded according to the chosen percentage. Try it and see what happens!": "此用户界面允许您使用StableDiffusion的扩绘功能扩展现有图像。上传图像，输入提示，选择模型类型和扩展方向，并自定义生成设置。图像将根据选择的百分比进行扩展。试试看会发生什么！",
  "Enter GLIGEN phrases": "输入GLIGEN短语",
  "Enter GLIGEN boxes": "输入GLIGEN框",
  "NeuroSandboxWebUI - StableDiffusion (gligen)": "NeuroSandboxWebUI - StableDiffusion（GLIGEN）",
  "This user interface allows you to generate images using Stable Diffusion and insert objects using GLIGEN. Select the Stable Diffusion model, customize the generation settings, enter a prompt, GLIGEN phrases, and bounding boxes. Try it and see what happens!": "此用户界面允许您使用Stable Diffusion生成图像并使用GLIGEN插入对象。选择Stable Diffusion模型，自定义生成设置，输入提示、GLIGEN短语和边界框。试试看会发生什么！",
  "Source Prompt": "源提示",
  "Source Negative Prompt": "源负面提示",
  "Target Prompt": "目标提示",
  "Target Negative Prompt": "目标负面提示",
  "Guidance Scale": "引导尺度",
  "NeuroSandboxWebUI - StableDiffusion (DiffEdit)": "NeuroSandboxWebUI - StableDiffusion（DiffEdit）",
  "This user interface allows you to edit images using DiffEdit. Upload an image, provide source and target prompts, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用DiffEdit编辑图像。上传图像，提供源和目标提示，并自定义生成设置。试试看会发生什么！",
  "Conditioning Image": "条件图像",
  "Conditioning Subject": "条件主体",
  "Target Subject": "目标主体",
  "Inference Steps": "推理步骤",
  "Output Format": "输出格式",
  "Generated Image": "生成的图像",
  "NeuroSandboxWebUI - BlipDiffusion": "NeuroSandboxWebUI - BlipDiffusion",
  "This interface allows you to generate images using BlipDiffusion. Upload a conditioning image, provide text prompts and subjects, and customize generation parameters.": "此界面允许您使用BlipDiffusion生成图像。上传条件图像，提供文本提示和主体，并自定义生成参数。",
  "Initial GIF": "初始GIF",
  "Strength (Initial GIF)": "强度（初始GIF）",
  "Select Motion LORA (Optional)": "选择运动LORA（可选）",
  "Frames": "帧数",
  "AnimateDiff Settings": "AnimateDiff设置",
  "Generated GIF": "生成的GIF",
  "NeuroSandboxWebUI - StableDiffusion (animatediff)": "NeuroSandboxWebUI - StableDiffusion（AnimateDiff）",
  "This user interface allows you to enter a prompt and generate animated GIFs using AnimateDiff. You can select the model and customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入提示并使用AnimateDiff生成动画GIF。您可以选择模型并使用滑块自定义生成设置。试试看会发生什么！",
  "Video Length (frames)": "视频长度（帧数）",
  "Video Duration (seconds)": "视频持续时间（秒）",
  "HotShot-XL Settings": "HotShot-XL设置",
  "NeuroSandboxWebUI - Hotshot-XL": "NeuroSandboxWebUI - Hotshot-XL",
  "This user interface allows you to generate animated GIFs using Hotshot-XL. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Hotshot-XL生成动画GIF。输入提示并自定义生成设置。试试看会发生什么！",
  "<h3>SVD Settings (mp4)</h3>": "SVD设置（mp4）",
  "Motion Bucket ID": "运动桶ID",
  "Noise Augmentation Strength": "噪声增强强度",
  "FPS": "帧率",
  "Decode Chunk Size": "解码块大小",
  "<h3>I2VGen-xl Settings (gif)</h3>": "I2VGen-xl设置（gif）",
  "Generated video": "生成的视频",
  "NeuroSandboxWebUI - StableDiffusion (video)": "NeuroSandboxWebUI - StableDiffusion（视频）",
  "This user interface allows you to enter an initial image and generate a video using StableVideoDiffusion(mp4) and I2VGen-xl(gif). You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入初始图像并使用StableVideoDiffusion（mp4）和I2VGen-xl（gif）生成视频。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "Generated RGBs": "生成的RGB图像",
  "Generated Depth images": "生成的深度图像",
  "NeuroSandboxWebUI - StableDiffusion (LDM3D)": "NeuroSandboxWebUI - StableDiffusion（LDM3D）",
  "This user interface allows you to enter a prompt and generate RGB and Depth images using LDM3D. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入提示并使用LDM3D生成RGB和深度图像。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "Max Length": "最大长度",
  "NeuroSandboxWebUI - StableDiffusion 3 (txt2img)": "NeuroSandboxWebUI - StableDiffusion 3（文本到图像）",
  "This user interface allows you to enter any text and generate images using Stable Diffusion 3. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本并使用Stable Diffusion 3生成图像。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - StableDiffusion 3 (img2img)": "NeuroSandboxWebUI - StableDiffusion 3（图像到图像）",
  "This user interface allows you to enter any text and initial image to generate new images using Stable Diffusion 3. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本和初始图像，使用Stable Diffusion 3生成新图像。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - StableDiffusion 3 (ControlNet)": "NeuroSandboxWebUI - StableDiffusion 3（ControlNet）",
  "This user interface allows you to use ControlNet models with Stable Diffusion 3. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您将ControlNet模型与Stable Diffusion 3一起使用。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - StableDiffusion 3 (Inpaint)": "NeuroSandboxWebUI - StableDiffusion 3（修复）",
  "This user interface allows you to perform inpainting using Stable Diffusion 3. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您使用Stable Diffusion 3进行图像修复。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "Prior Steps": "先验步骤",
  "Prior Guidance Scale": "先验引导尺度",
  "Decoder Steps": "解码器步骤",
  "Decoder Guidance Scale": "解码器引导尺度",
  "NeuroSandboxWebUI - StableDiffusion (cascade)": "NeuroSandboxWebUI - StableDiffusion（级联）",
  "This user interface allows you to enter a prompt and generate images using Stable Cascade. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入提示并使用Stable Cascade生成图像。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "IP-Adapter Image": "IP-Adapter图像",
  "T2I IP-Adapter Settings": "T2I IP-Adapter设置",
  "NeuroSandboxWebUI - StableDiffusion (T2I IP-Adapter)": "NeuroSandboxWebUI - StableDiffusion（T2I IP-Adapter）",
  "This user interface allows you to generate images using T2I IP-Adapter. Upload an image, enter a prompt, select a Stable Diffusion model, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用T2I IP-Adapter生成图像。上传图像，输入提示，选择Stable Diffusion模型，并自定义生成设置。试试看会发生什么！",
  "Face image": "人脸图像",
  "Scale (Face image)": "缩放（人脸图像）",
  "IP-Adapter FaceID Settings": "IP-Adapter FaceID设置",
  "NeuroSandboxWebUI - StableDiffusion (IP-Adapter FaceID)": "NeuroSandboxWebUI - StableDiffusion（IP-Adapter FaceID）",
  "This user interface allows you to generate images using IP-Adapter FaceID. Upload a face image, enter a prompt, select a Stable Diffusion model, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用IP-Adapter FaceID生成图像。上传人脸图像，输入提示，选择Stable Diffusion模型，并自定义生成设置。试试看会发生什么！",
  "Riffusion Settings": "Riffusion设置",
  "NeuroSandboxWebUI - Riffusion (Text-to-Image)": "NeuroSandboxWebUI - Riffusion（文本到图像）",
  "Generate a spectrogram image from text using Riffusion.": "使用Riffusion从文本生成频谱图图像。",
  "Input spectrogram image": "输入频谱图图像",
  "Generated audio": "生成的音频",
  "NeuroSandboxWebUI - Riffusion (Image-to-Audio)": "NeuroSandboxWebUI - Riffusion（图像到音频）",
  "Convert a spectrogram image to audio using Riffusion.": "使用Riffusion将频谱图图像转换为音频。",
  "Convert": "转换",
  "Input audio": "输入音频",
  "Generated spectrogram image": "生成的频谱图图像",
  "NeuroSandboxWebUI - Riffusion (Audio-to-Image)": "NeuroSandboxWebUI - Riffusion（音频到图像）",
  "Convert audio to a spectrogram image using Riffusion.": "使用Riffusion将音频转换为频谱图图像。",
  "Kandinsky Version": "Kandinsky版本",
  "NeuroSandboxWebUI - Kandinsky (txt2img)": "NeuroSandboxWebUI - Kandinsky（文本到图像）",
  "This user interface allows you to generate images using Kandinsky models. You can select between versions 2.1, 2.2, and 3, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Kandinsky模型生成图像。您可以在2.1、2.2和3版本之间选择，并自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - Kandinsky (img2img)": "NeuroSandboxWebUI - Kandinsky（图像到图像）",
  "NeuroSandboxWebUI - Kandinsky (inpaint)": "NeuroSandboxWebUI - Kandinsky（修复）",
  "This user interface allows you to perform inpainting using Kandinsky models. You can select between versions 2.1 and 2.2, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Kandinsky模型进行图像修复。您可以在2.1和2.2版本之间选择，并自定义生成设置。试试看会发生什么！",
  "Select Flux model": "选择Flux模型",
  "Select safetensors Flux model (GGUF if enabled quantize)": "选择 safetensors Flux 模型（如果启用量化则选择 GGUF）",
  "Enable Quantize": "启用量化",
  "Flux txt2img Settings": "Flux txt2img设置",
  "Flux img2img Settings": "Flux img2img设置",
  "Flux inpaint Settings": "Flux inpaint设置",
  "Flux ControlNet Settings": "Flux ControlNet设置",
  "NeuroSandboxWebUI - Flux (txt2img)": "NeuroSandboxWebUI - Flux（文本到图像）",
  "This user interface allows you to generate images using Flux models. You can select between Schnell and Dev models, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Flux模型生成图像。您可以在Schnell和Dev模型之间选择，并自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - Flux (img2img)": "NeuroSandboxWebUI - Flux（图像到图像）",
  "This user interface allows you to generate images from existing images using Flux models. Upload an initial image, enter a prompt, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Flux模型从现有图像生成新图像。上传初始图像，输入提示，并自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - Flux (inpaint)": "NeuroSandboxWebUI - Flux（修复）",
  "This user interface allows you to perform inpainting using Flux models. Upload an initial image, draw a mask, enter a prompt, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Flux模型进行图像修复。上传初始图像，绘制蒙版，输入提示，并自定义生成设置。试试看会发生什么！",
  "Control image": "控制图像",
  "Select Flux base model": "选择Flux基础模型",
  "Control Mode": "控制模式",
  "ControlNet Conditioning Scale": "ControlNet条件缩放",
  "NeuroSandboxWebUI - Flux (ControlNet)": "NeuroSandboxWebUI - Flux（ControlNet）",
  "This user interface allows you to generate images using Flux ControlNet. Upload a control image, enter a prompt, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Flux ControlNet生成图像。上传控制图像，输入提示，并自定义生成设置。试试看会发生什么！",
  "HunyuanDiT Settings": "HunyuanDiT设置",
  "NeuroSandboxWebUI - HunyuanDiT (txt2img)": "NeuroSandboxWebUI - HunyuanDiT（文本到图像）",
  "This user interface allows you to generate images using HunyuanDiT model. Enter a prompt (in English or Chinese) and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用HunyuanDiT模型生成图像。输入提示（英文或中文）并自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - HunyuanDiT (ControlNet)": "NeuroSandboxWebUI - HunyuanDiT（ControlNet）",
  "This user interface allows you to generate images using HunyuanDiT ControlNet models. Enter a prompt, upload an input image, select a ControlNet model, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用HunyuanDiT ControlNet模型生成图像。输入提示，上传输入图像，选择ControlNet模型，并自定义生成设置。试试看会发生什么！",
  "Lumina-T2X Settings": "Lumina-T2X设置",
  "NeuroSandboxWebUI - Lumina-T2X": "NeuroSandboxWebUI - Lumina-T2X",
  "This user interface allows you to generate images using the Lumina-T2X model. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Lumina-T2X模型生成图像。输入提示并自定义生成设置。试试看会发生什么！",
  "Kolors Settings": "Kolors设置",
  "NeuroSandboxWebUI - Kolors (txt2img)": "NeuroSandboxWebUI - Kolors（文本到图像）",
  "This user interface allows you to generate images using the Kolors model. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Kolors模型生成图像。输入提示并自定义生成设置。试试看会发生什么！",
  "NeuroSandboxWebUI - Kolors (img2img)": "NeuroSandboxWebUI - Kolors（图像到图像）",
  "NeuroSandboxWebUI - Kolors (ip-adapter-plus)": "NeuroSandboxWebUI - Kolors（ip-adapter-plus）",
  "AuraFlow Settings": "AuraFlow设置",
  "Enable AuraSR": "启用AuraSR",
  "NeuroSandboxWebUI - AuraFlow": "NeuroSandboxWebUI - AuraFlow",
  "This user interface allows you to generate images using the AuraFlow model. Enter a prompt and customize the generation settings. You can also enable AuraSR for 4x upscaling of the generated image. Try it and see what happens!": "此用户界面允许您使用AuraFlow模型生成图像。输入提示并自定义生成设置。您还可以启用AuraSR对生成的图像进行4倍放大。试试看会发生什么！",
  "Würstchen Settings": "Würstchen设置",
  "NeuroSandboxWebUI - Würstchen": "NeuroSandboxWebUI - Würstchen",
  "This user interface allows you to generate images using the Würstchen model. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Würstchen模型生成图像。输入提示并自定义生成设置。试试看会发生什么！",
  "DeepFloyd IF Settings": "DeepFloyd IF设置",
  "NeuroSandboxWebUI - DeepFloyd IF (txt2img)": "NeuroSandboxWebUI - DeepFloyd IF（文本到图像）",
  "This user interface allows you to generate images using the DeepFloyd IF model. Enter a prompt and customize the generation settings. The process includes three stages of generation, each producing an image of increasing quality. Try it and see what happens!": "此用户界面允许您使用DeepFloyd IF模型生成图像。输入提示并自定义生成设置。生成过程包括三个阶段，每个阶段生成的图像质量逐步提高。试试看会发生什么！",
  "NeuroSandboxWebUI - DeepFloyd IF (img2img)": "NeuroSandboxWebUI - DeepFloyd IF（图像到图像）",
  "This interface allows you to generate images using DeepFloyd IF's image-to-image pipeline. Enter a prompt, upload an initial image, and customize the generation settings. The process includes three stages of generation, each producing an image of increasing quality. Try it and see what happens!": "此界面允许您使用DeepFloyd IF的图像到图像管道生成图像。输入提示，上传初始图像，并自定义生成设置。生成过程包括三个阶段，每个阶段生成的图像质量逐步提高。试试看会发生什么！",
  "NeuroSandboxWebUI - DeepFloyd IF (inpaint)": "NeuroSandboxWebUI - DeepFloyd IF（修复）",
  "This interface allows you to perform inpainting using DeepFloyd IF. Enter a prompt, upload an initial image and a mask image, and customize the generation settings. The process includes three stages of generation, each producing an image of increasing quality. Try it and see what happens!": "此界面允许您使用DeepFloyd IF进行图像修复。输入提示，上传初始图像和蒙版图像，并自定义生成设置。生成过程包括三个阶段，每个阶段生成的图像质量逐步提高。试试看会发生什么！",
  "PixArt Version": "PixArt版本",
  "PixArt Settings": "PixArt设置",
  "NeuroSandboxWebUI - PixArt": "NeuroSandboxWebUI - PixArt",
  "This user interface allows you to generate images using PixArt models. You can select between Alpha and Sigma versions, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用PixArt模型生成图像。您可以在Alpha和Sigma版本之间选择，并自定义生成设置。试试看会发生什么！",
  "PlaygroundV2.5 Settings": "PlaygroundV2.5设置",
  "NeuroSandboxWebUI - PlaygroundV2.5": "NeuroSandboxWebUI - PlaygroundV2.5",
  "This user interface allows you to generate images using PlaygroundV2.5. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用PlaygroundV2.5生成图像。输入提示并自定义生成设置。试试看会发生什么！",
  "Face Detection Batch Size": "人脸检测批量大小",
  "Wav2Lip Batch Size": "Wav2Lip批量大小",
  "Resize Factor": "调整大小因子",
  "Crop": "裁剪",
  "Enable no smooth": "启用无平滑",
  "Generated lip-sync": "生成的唇形同步",
  "NeuroSandboxWebUI - Wav2Lip": "NeuroSandboxWebUI - Wav2Lip",
  "This user interface allows you to generate talking head videos by combining an image and an audio file using Wav2Lip. Upload an image and an audio file, and click Generate to create the talking head video. Try it and see what happens!": "此用户界面允许您使用Wav2Lip通过组合图像和音频文件生成说话的头像视频。上传图像和音频文件，然后点击生成以创建说话的头像视频。试试看会发生什么！",
  "Animate": "动画",
  "Source image": "源图像",
  "Driving video": "驱动视频",
  "NeuroSandboxWebUI - LivePortrait": "NeuroSandboxWebUI - LivePortrait",
  "This user interface allows you to animate a source image based on the movements in a driving video using LivePortrait. Upload a source image and a driving video, then click Generate to create the animated video. Try it and see what happens!": "此用户界面允许您使用LivePortrait根据驱动视频中的动作为源图像制作动画。上传源图像和驱动视频，然后点击生成以创建动画视频。试试看会发生什么！",
  "Number of Frames": "帧数",
  "ModelScope Settings": "ModelScope设置",
  "NeuroSandboxWebUI - ModelScope": "NeuroSandboxWebUI - ModelScope",
  "This user interface allows you to generate videos using ModelScope. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用ModelScope生成视频。输入提示并自定义生成设置。试试看会发生什么！",
  "Video to enhance (optional)": "要增强的视频（可选）",
  "Enable Video Enhancement": "启用视频增强",
  "ZeroScope 2 Settings": "ZeroScope 2设置",
  "NeuroSandboxWebUI - ZeroScope 2": "NeuroSandboxWebUI - ZeroScope 2",
  "This user interface allows you to generate and enhance videos using ZeroScope 2 models. You can enter a text prompt, upload an optional video for enhancement, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用ZeroScope 2模型生成和增强视频。您可以输入文本提示，上传可选的视频进行增强，并自定义生成设置。试试看会发生什么！",
  "Select CogVideoX model version": "选择CogVideoX模型版本",
  "Text2Video": "文本到视频",
  "Image2Video": "图像到视频",
  "Video2Video": "视频到视频",
  "CogVideoX T2V Settings": "CogVideoX 文本到视频设置",
  "CogVideoX I2V Settings": "CogVideoX 图像到视频设置",
  "CogVideoX V2V Settings": "CogVideoX 视频到视频设置",
  "NeuroSandboxWebUI - CogVideoX (Text2Video)": "NeuroSandboxWebUI - CogVideoX（文本到视频）",
  "NeuroSandboxWebUI - CogVideoX (Image2Video)": "NeuroSandboxWebUI - CogVideoX（图像到视频）",
  "NeuroSandboxWebUI - CogVideoX (Video2Video)": "NeuroSandboxWebUI - CogVideoX（视频到视频）",
  "This user interface allows you to generate videos from text using CogVideoX (Text2Video). Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用CogVideoX（文本到视频）从文本生成视频。输入提示并自定义生成设置。试试看会发生什么！",
  "This user interface allows you to generate videos from images using CogVideoX (Image2Video). Upload an image, enter a prompt, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用CogVideoX（图像到视频）从图像生成视频。上传图像，输入提示，并自定义生成设置。试试看会发生什么！",
  "This user interface allows you to generate videos from videos using CogVideoX (Video2Video). Upload a video, enter a prompt, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用CogVideoX（视频到视频）从视频生成视频。上传视频，输入提示并自定义生成设置。试试看会发生什么！",
  "Video Length": "视频长度",
  "Latte Settings": "Latte设置",
  "NeuroSandboxWebUI - Latte": "NeuroSandboxWebUI - Latte",
  "This user interface allows you to generate GIFs using Latte. Enter a prompt and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Latte生成GIF。输入提示并自定义生成设置。试试看会发生什么！",
  "Texture Resolution": "纹理分辨率",
  "Foreground Ratio": "前景比例",
  "Remesh Option": "重新网格化选项",
  "Generated 3D object": "生成的3D对象",
  "NeuroSandboxWebUI - StableFast3D": "NeuroSandboxWebUI - StableFast3D",
  "This user interface allows you to generate 3D objects from images using StableFast3D. Upload an image and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用StableFast3D从图像生成3D对象。上传图像并自定义生成设置。试试看会发生什么！",
  "Frame size": "帧大小",
  "Shap-E Settings": "Shap-E设置",
  "NeuroSandboxWebUI - Shap-E": "NeuroSandboxWebUI - Shap-E",
  "This user interface allows you to generate 3D objects using Shap-E. You can enter a text prompt or upload an initial image, and customize the generation settings. Try it and see what happens!": "此用户界面允许您使用Shap-E生成3D对象。您可以输入文本提示或上传初始图像，并自定义生成设置。试试看会发生什么！",
  "Input file (Image for 3D-U and 3D-P, MP4 video for 4D)": "输入文件（3D-U和3D-P使用图像，4D使用MP4视频）",
  "Version": "版本",
  "Elevation Degree (for 3D-P only)": "仰角（仅适用于3D-P）",
  "Generated output": "生成的输出",
  "NeuroSandboxWebUI - SV34D": "NeuroSandboxWebUI - SV34D",
  "This interface allows you to generate 3D and 4D content using SV34D models. Upload an image (PNG, JPG, JPEG) for 3D-U and 3D-P versions, or an MP4 video for 4D version. Select the version and customize settings as needed.": "此界面允许您使用SV34D模型生成3D和4D内容。上传图像（PNG、JPG、JPEG）用于3D-U和3D-P版本，或上传MP4视频用于4D版本。选择版本并根据需要自定义设置。",
  "NeuroSandboxWebUI - Zero123Plus": "NeuroSandboxWebUI - Zero123Plus",
  "This user interface allows you to generate 3D-like images using Zero123Plus. Upload an input image and customize the number of inference steps. Try it and see what happens!": "此用户界面允许您使用Zero123Plus生成类3D图像。上传输入图像并自定义推理步骤数。试试看会发生什么！",
  "Audio Length (seconds)": "音频长度（秒）",
  "Audio Start (seconds)": "音频开始时间（秒）",
  "Number of Waveforms": "波形数量",
  "StableAudio Settings": "StableAudio设置",
  "NeuroSandboxWebUI - StableAudio": "NeuroSandboxWebUI - StableAudio",
  "This user interface allows you to enter any text and generate audio using StableAudio. You can customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本并使用StableAudio生成音频。您可以使用滑块自定义生成设置。试试看会发生什么！",
  "Melody audio (optional)": "旋律音频（可选）",
  "Select AudioCraft model": "选择AudioCraft模型",
  "Select model type": "选择模型类型",
  "Duration (seconds)": "持续时间（秒）",
  "Top K": "Top K",
  "Enable Voice Conversion": "启用语音转换",
  "Source wav": "源wav",
  "Target wav": "目标wav",
  "Enable CDVAE": "启用CDVAE",
  "Enable TAESD": "启用TAESD",
  "Enable Two-step CFG (Musicgen and Audiogen models only)": "启用两步CFG（仅适用于Musicgen和Audiogen模型）",
  "Enable Sampling (Musicgen and Audiogen models only)": "启用采样（仅适用于Musicgen和Audiogen模型）",
  "Min CFG coef (Magnet model only)": "最小CFG系数（仅限Magnet模型）",
  "Max CFG coef (Magnet model only)": "最大CFG系数（仅限Magnet模型）",
  "Enable Multiband Diffusion (Musicgen model only)": "启用多频带扩散（仅限Musicgen模型）",
  "Select output format (Works only without Multiband Diffusion)": "选择输出格式（仅在不使用多频带扩散时有效）",
  "Mel-Spectrogram": "梅尔频谱图",
  "NeuroSandboxWebUI - AudioCraft": "NeuroSandboxWebUI - AudioCraft",
  "This user interface allows you to enter any text and generate audio using AudioCraft. You can select the model and customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本并使用AudioCraft生成音频。您可以选择模型并使用滑块自定义生成设置。试试看会发生什么！",
  "Select AudioLDM 2 model": "选择AudioLDM 2模型",
  "Length (seconds)": "长度（秒）",
  "Waveforms number": "波形数量",
  "AudioLDM 2 Settings": "AudioLDM 2设置",
  "NeuroSandboxWebUI - AudioLDM 2": "NeuroSandboxWebUI - AudioLDM 2",
  "This user interface allows you to enter any text and generate audio using AudioLDM 2. You can select the model and customize the generation settings from the sliders. Try it and see what happens!": "此用户界面允许您输入任何文本并使用AudioLDM 2生成音频。您可以选择模型并使用滑块自定义生成设置。试试看会发生什么！",
  "Enter text for the request": "输入请求文本",
  "Select voice preset": "选择语音预设",
  "Max length": "最大长度",
  "Fine temperature": "精细温度",
  "Coarse temperature": "粗糙温度",
  "Bark Settings": "Bark设置",
  "NeuroSandboxWebUI - SunoBark": "NeuroSandboxWebUI - SunoBark",
  "This user interface allows you to enter text and generate audio using SunoBark. You can select the voice preset and customize the max length. Try it and see what happens!": "此用户界面允许您输入文本并使用SunoBark生成音频。您可以选择语音预设并自定义最大长度。试试看会发生什么！",
  "Select RVC model": "选择RVC模型",
  "RVC Method": "RVC方法",
  "Up-key": "升调",
  "Index rate": "索引率",
  "Filter radius": "过滤半径",
  "Resample-Sr": "重采样率",
  "RMS Mixrate": "RMS混合率",
  "Protection": "保护",
  "RVC Settings": "RVC设置",
  "Processed audio": "处理后的音频",
  "NeuroSandboxWebUI - RVC": "NeuroSandboxWebUI - RVC",
  "This user interface allows you to process audio using RVC (Retrieval-based Voice Conversion). Upload an audio file, select an RVC model, and choose the output format. Try it and see what happens!": "此用户界面允许您使用RVC（基于检索的语音转换）处理音频。上传音频文件，选择RVC模型，并选择输出格式。试试看会发生什么！",
  "Conversion": "转换",
  "Audio file to separate": "要分离的音频文件",
  "Normalization Threshold": "归一化阈值",
  "Sample Rate": "采样率",
  "Vocals": "人声",
  "Instrumental": "乐器声",
  "NeuroSandboxWebUI - UVR": "NeuroSandboxWebUI - UVR",
  "This user interface allows you to upload an audio file and separate it into vocals and instrumental using Ultimate Vocal Remover (UVR). Try it and see what happens!": "此用户界面允许您上传音频文件，并使用Ultimate Vocal Remover（UVR）将其分离为人声和乐器声。试试看会发生什么！",
  "Separate": "分离",
  "Vocal": "人声",
  "NeuroSandboxWebUI - Demucs": "NeuroSandboxWebUI - Demucs",
  "This user interface allows you to upload an audio file and separate it into vocal and instrumental using Demucs. Try it and see what happens!": "此用户界面允许您上传音频文件，并使用Demucs将其分离为人声和乐器声。试试看会发生什么！",
  "Image to modify": "要修改的图像",
  "Remove BackGround": "移除背景",
  "Enable FaceRestore": "启用人脸修复",
  "Fidelity weight (For FaceRestore)": "保真度权重（用于人脸修复）",
  "Upscale (For FaceRestore)": "放大（用于人脸修复）",
  "Enable PixelOE": "启用PixelOE",
  "PixelOE Mode": "PixelOE模式",
  "Target Size (For PixelOE)": "目标大小（用于PixelOE）",
  "Patch Size (For PixelOE)": "补丁大小（用于PixelOE）",
  "Thickness (For PixelOE)": "厚度（用于PixelOE）",
  "contrast (For PixelOE)": "对比度（用于PixelOE）",
  "saturation (For PixelOE)": "饱和度（用于PixelOE）",
  "Enable DDColor": "启用DDColor",
  "Input Size (For DDColor)": "输入大小（用于DDColor）",
  "Enable DownScale": "启用缩小",
  "DownScale Factor": "缩小因子",
  "Enable Format Changer": "启用格式转换器",
  "New Image Format": "新图像格式",
  "Enable Encryption": "启用加密",
  "Enable Decryption": "启用解密",
  "Decryption Key": "解密密钥",
  "Modified image": "修改后的图像",
  "NeuroSandboxWebUI - Extras (Image)": "NeuroSandboxWebUI - 附加功能（图像）",
  "This interface allows you to modify images": "此界面允许您修改图像",
  "Modify": "修改",
  "Video to modify": "要修改的视频",
  "New Video Format": "新视频格式",
  "Modified video": "修改后的视频",
  "NeuroSandboxWebUI - Extras (Video)": "NeuroSandboxWebUI - 附加功能（视频）",
  "This interface allows you to modify videos": "此界面允许您修改视频",
  "Audio to modify": "要修改的音频",
  "New Audio Format": "新音频格式",
  "Enable AudioSR": "启用AudioSR",
  "Enable Downscale": "启用缩小",
  "Downscale Factor": "缩小因子",
  "Modified audio": "修改后的音频",
  "NeuroSandboxWebUI - Extras (Audio)": "NeuroSandboxWebUI - 附加功能（音频）",
  "This interface allows you to modify audio files": "此界面允许您修改音频文件",
  "Image to upscale": "要放大的图像",
  "Input video": "输入视频",
  "Select model": "选择模型",
  "Enable Face Enhance": "启用人脸增强",
  "Tile": "平铺",
  "Tile pad": "平铺填充",
  "Pre pad": "预填充",
  "Denoise strength": "降噪强度",
  "Face Enhance Settings": "人脸增强设置",
  "Upscaled image": "放大后的图像",
  "Upscaled video": "放大后的视频",
  "NeuroSandboxWebUI - Upscale (Real-ESRGAN)": "NeuroSandboxWebUI - 放大（Real-ESRGAN）",
  "This user interface allows you to upload an image and upscale it using Real-ESRGAN models": "此用户界面允许您上传图像并使用Real-ESRGAN模型进行放大",
  "Source Image": "源图像",
  "Target Image": "目标图像",
  "Target Video": "目标视频",
  "Enable many faces": "启用多个人脸",
  "Reference face position": "参考人脸位置",
  "Reference frame number": "参考帧号",
  "Fidelity weight": "保真度权重",
  "FaceSwap (Roop) Settings": "人脸交换（Roop）设置",
  "Processed image": "处理后的图像",
  "Processed video": "处理后的视频",
  "NeuroSandboxWebUI - FaceSwap (Roop)": "NeuroSandboxWebUI - 人脸交换（Roop）",
  "This user interface allows you to perform face swapping on images or videos and optional face restoration.": "此用户界面允许您在图像或视频上执行人脸交换，并可选择进行人脸修复。",
  "Swap": "交换",
  "Upload file": "上传文件",
  "Metadata": "元数据",
  "NeuroSandboxWebUI - Metadata-Info": "NeuroSandboxWebUI - 元数据信息",
  "This interface allows you to view generation metadata for image, video, and audio files.": "此界面允许您查看图像、视频和音频文件的生成元数据。",
  "View": "查看",
  "Image": "图像",
  "Video": "视频",
  "Audio": "音频",
  "Upscale (Real-ESRGAN)": "放大（Real-ESRGAN）",
  "FaceSwap": "人脸交换",
  "Metadata-Info": "元数据信息",
  "Online Wiki": "在线维基",
  "Local Wiki": "本地维基",
  "Wiki Content": "维基内容",
  "NeuroSandboxWebUI - Wiki": "NeuroSandboxWebUI - 维基",
  "This interface displays the Wiki content from the specified URL or local file.": "此界面显示来自指定URL或本地文件的维基内容。",
  "Learn": "学习",
  "Output Files": "输出文件",
  "Text": "文本",
  "3D Model": "3D模型",
  "Select Style (optional)": "选择风格（可选）",
  "NeuroSandboxWebUI - Gallery": "NeuroSandboxWebUI - 图库",
  "This interface allows you to view files from the outputs directory": "此界面允许您查看输出目录中的文件",
  "NeuroSandboxWebUI - ModelDownloader": "NeuroSandboxWebUI - 模型下载器",
  "Model URL": "模型网址",
  "Select Diffusers model": "选择扩散模型",
  "NeuroSandboxWebUI - CogView3-Plus": "NeuroSandboxWebUI - CogView3-Plus",
  "This user interface allows you to enter any text and generate images using Cogview3-plus. You can customize the generation settings from the sliders. Try it and see what happens!": "这个用户界面允许您输入任何文本，并使用Cogview3-plus生成图像。您可以通过滑块自定义生成设置。试试看会发生什么！",
  "This interface allows you to download various types of models": "此界面允许您下载各种类型的模型",
  "Download": "下载",
  "Share Mode": "共享模式",
  "Debug Mode": "调试模式",
  "Monitoring Mode": "监控模式",
  "Enable AutoLaunch": "启用自动启动",
  "Show API": "显示API",
  "Open API": "打开API",
  "Queue max size": "队列最大大小",
  "Queue status update rate": "队列状态更新率",
  "Gradio Auth": "Gradio认证",
  "Server Name": "服务器名称",
  "Server Port": "服务器端口",
  "Hugging Face Token": "Hugging Face令牌",
  "Theme": "主题",
  "Enable Custom Theme": "启用自定义主题",
  "Primary Hue": "主要色调",
  "Secondary Hue": "次要色调",
  "Neutral Hue": "中性色调",
  "Spacing Size": "间距大小",
  "Radius Size": "圆角大小",
  "Text Size": "文本大小",
  "Font": "字体",
  "Monospaced Font": "等宽字体",
  "Theme builder": "主题构建器",
  "NeuroSandboxWebUI - Settings": "NeuroSandboxWebUI - 设置",
  "This user interface allows you to change settings of the application": "此用户界面允许您更改应用程序的设置",
  "Update": "更新",
  "GPU Total Memory": "GPU总内存",
  "GPU Used Memory": "GPU已用内存",
  "GPU Free Memory": "GPU可用内存",
  "GPU Temperature": "GPU温度",
  "CPU Temperature": "CPU温度",
  "RAM Total": "总RAM",
  "RAM Used": "已用RAM",
  "RAM Free": "可用RAM",
  "Disk Total Space": "磁盘总空间",
  "Disk Free Space": "磁盘可用空间",
  "Application Folder Size": "应用程序文件夹大小",
  "NeuroSandboxWebUI - System": "NeuroSandboxWebUI - 系统",
  "This interface displays system information": "此界面显示系统信息",
  "Display": "显示",
  "LLM": "LLM",
  "TTS-STT": "TTS-STT",
  "MMS": "MMS",
  "SeamlessM4Tv2": "SeamlessM4Tv2",
  "LibreTranslate": "LibreTranslate",
  "StableDiffusion": "StableDiffusion",
  "Kandinsky": "Kandinsky",
  "Flux": "Flux",
  "HunyuanDiT": "HunyuanDiT",
  "Lumina-T2X": "Lumina-T2X",
  "Kolors": "Kolors",
  "AuraFlow": "AuraFlow",
  "Würstchen": "Würstchen",
  "DeepFloydIF": "DeepFloydIF",
  "PixArt": "PixArt",
  "PlaygroundV2.5": "PlaygroundV2.5",
  "Wav2Lip": "Wav2Lip",
  "LivePortrait": "LivePortrait",
  "ModelScope": "ModelScope",
  "ZeroScope2": "ZeroScope2",
  "CogVideoX": "CogVideoX",
  "Latte": "Latte",
  "StableFast3D": "StableFast3D",
  "Shap-E": "Shap-E",
  "SV34D": "SV34D",
  "Zero123Plus": "Zero123Plus",
  "StableAudio": "StableAudio",
  "AudioCraft": "AudioCraft",
  "AudioLDM2": "AudioLDM2",
  "SunoBark": "SunoBark",
  "RVC": "RVC",
  "UVR": "UVR",
  "Demucs": "Demucs",
  "Extras": "附加功能",
  "Wiki": "维基",
  "Gallery": "图库",
  "ModelDownloader": "模型下载器",
  "Settings": "设置",
  "System": "系统",
  "3D": "3D",
  "Interface": "界面",
  "Reload interface": "重新加载界面",
  "Close terminal": "关闭终端",
  "Outputs": "输出",
  "GitHub": "GitHub",
  "Hugging Face": "Hugging Face",
  "Welcome to NeuroSandboxWebUI!": "欢迎使用NeuroSandboxWebUI！",
  "Language": "语言"
}